---
title       : Study of the mtcars data set in R
subtitle    : Regression Models course project assignment
author      : StefMT2970
output      : pdf_document
---

```{r, echo=FALSE}
setwd("d:/dev/app/gitrepo/mtCars")
library(ggplot2)
library(car)
library(leaps)
library(gvlma)
#library(psych)
#library(pastecs)

# preparing the data set
mtcars$am <- factor(mtcars$am, labels =c("automatic","manual"))
mtcars$gear <- as.factor(mtcars$gear)
mtcars$cyl <- as.factor(mtcars$cyl)

```

## Overview
The assignment requires an investigation into the R data set "mtcars".
The data set is for a collection of cars, and we are asked :

- Is an automatic or manual transmission better for MPG ?
- Quantify the MPG difference between automatic and manual transmissions ?

## The art of statistics
In a way statistics resembles dumb number crunching. The algorithm applied (however sophisticated) is not capable of giving an *interpretation* to the outcome nor understanding the wider context. This paper attempts to apply statistics to find answers to the questions asked above, but before we jump into the math, let's summarise what we know about the topic.
The data set under investigation was extracted from the 1974 Motor Trend US magazine, a time when myself I was still in the business of playing with toy cars. 
From the theory of mechanics we now that weight is the most influential factor in fuel consumption ($F=ma$). Automatic transmissions normally lead to consuming extra fuel. 
So let's move on and explore the data set and after that see if the math theory supports the hypotheses that an automatic transmission consumes more fuel than a manual transmission.


## Exploratory data analysis
The data frame has 32 observations on 11 variables. 19 observations are for automatic transmission cars and 13 for manual transmission cars. There are no records which allow to compare manual vs automatic transmission for the same models (no paired test possible).

Looking at the 2 simple box plots in the appendix shows that the automatic transmission cars in the data set have lower MPG (=higher fuel consumption) than manual transmission cars. The second box plot shows that in this data set the automatic cars tend to be much heavier. The scatterplots in the appendix reveal that other factors than transmission type are more correlated with MPG. Let's see what regression models have to say about that.

## The science of statistics
Considering the data set is very small, we can afford to do a best subset selection for linear regression models trying out all possible combinations.
The chunk of code below suggest that 3 variables (following the Bayesian information criteria) provides an optimal result. These 3 variables are wt, qsec and transmission type. (see appendix for Best Subset plots of Adjr2 and BIC).Weight was predicted by Newton's law already, but why qsec (1/4 mile time) ? It seems obvious that qsec is a result of applying horse power (hp) (generated from a certain displacement in cu.in. engine) to a weight and as such it is understandable that the algorithm detected that this variable explains a lot of the variance. Transmission type does not remove much variance.
```{r}
car.sum <- summary(regsubsets(mpg ~., data = mtcars))
car.sum$which[which.min(car.sum$bic), 5:10]
```

Let's double check above by having a hierarchy of models and applying anova. It shows that the third model is on the edge ($p < 0.05$) of still being significant. The impact of transmission type on fuel consumption in this data set is not strong.
```{r}
car.fit1 <- lm(mpg ~ wt, data = mtcars)
car.fit2 <- lm(mpg ~ wt + qsec, data = mtcars)
car.fit3 <- lm(mpg ~ wt + qsec + am, data = mtcars)
anova(car.fit1, car.fit2, car.fit3)
```



```{r , echo=FALSE}
mt <- mtcars
mt.fit <- lm(mpg ~ wt + qsec + am, data = mtcars)
mt$residuals<-resid(mt.fit)
mt$standardized.residuals <- rstandard(mt.fit)
mt$studentized.residuals <- rstudent(mt.fit)
mt$cooks.distance<-cooks.distance(mt.fit)
mt$dfbeta <- dfbeta(mt.fit)
mt$dffit <- dffits(mt.fit)
mt$leverage <- hatvalues(mt.fit)
mt$covariance.ratios <- covratio(mt.fit)
mt$fitted.values <- mt.fit$fitted.values

```

The appendix contains the standard diagnostics plots for the selected model (mpg~wt+qsec+am) and show a slight deviation from a normal distribution. VIF shows a slight multicollinearity effect. The selected regression model shows that the coefficient for Manual transmission type is 2.9 (=2.9 MPG extra compared to automatic). 
I have to conclude that my initial hypotheses is supported by this data set. Statististics are in favour of supporting the hypotheses that manual transmission cars consume slightly less fuel than automatic transmission cars although the effect is small.
```{r}
coef(mt.fit); confint(mt.fit) 
vif(mt.fit)

```

## Appendix : graphs
```{r , echo=FALSE}
par(mfrow=c(2,2))
boxplot(mpg ~ am, data=mtcars,
        main = "MPG by Type of Transmission",
        ylab = "MPG (miles per gallon)")
boxplot(wt ~ am, data=mtcars,
        main ="Weight by Type of Transmission",
        ylab = "Weight (lb/1000)")
plot(car.sum$adjr2, xlab = "# of variables in regression",
                    ylab = "Adjusted R square",
                    main = "Best Subset selection",
                    type = "l")
plot(car.sum$bic,   xlab = "# of variables in regression",
                    main = "Best Subset selection",
                    ylab = "BIC",
                    type = "l")
plot(mt.fit)
par(mfrow=c(1,1))
```


```{r , echo=FALSE}
scatterplotMatrix( ~ qsec + wt + mpg + disp  + hp | am , data = mtcars,
                   spread = FALSE, 
                   smoother.args = list(lty=2, lwd =.5),
                   main = "Scatterplot for key variables in mtcars",
                   legend.pos ="bottomleft")

scatterplot(mpg ~ wt | am, data = mtcars,
            spread = TRUE,
            smoother = loessLine,
            smoother.args = list(lty=2, lwd =1, degree=1),
            main ="MPG vs Weight by transmission type",
            boxplot = "xy",
            grid = TRUE)

# scatterplot(mpg ~ qsec | am, data = mtcars, 
#             spread = TRUE,
#             smoother = loessLine,
#             smoother.args = list(lty=2, lwd =1, degree=1),
#             main ="MPG vs qsec by transmission type",            
#             boxplot = "xy",
#             grid = TRUE)
# scatterplot(hp ~ wt | am, data = mtcars, boxplot = "xy")

```



```{r , echo=FALSE}
par(mfrow=c(2,2))


par(mfrow=c(1,1))
influencePlot(mt.fit, main="influencePlot",
              sub = "size of circles represent influence")

#qqPlot(mt.fit)
#avPlots(mt.fit)
#outlierTest(mt.fit)

# #---Histogram of studentized residuals---
# 
# hist(mt$studentized.residuals)
# hist(rstudent(mt.fit))
# 
# #--Plot of residuals against fitted (predicted) values, with a flat line at the mean--
# plot(mt.fit$fitted.values,rstandard(mt.fit))
# abline(0, 0)

# histogram<-ggplot(mt, aes(studentized.residuals)) + 
#          theme(legend.position = "none") + 
#          geom_histogram(aes(y=..density..), colour="black", fill="white") +
#          labs(x = "Studentized Residual", y = "Density")
# histogram + stat_function(fun = dnorm, 
#                           args = list(mean = mean(mt$studentized.residuals, na.rm = TRUE), sd = sd(mt$studentized.residuals, na.rm = TRUE)), colour = "red", size = 1)
# 
# 
# scatter <- ggplot(mt, aes(fitted.values, studentized.residuals))
# scatter + geom_point() + geom_smooth(method = "lm", colour = "Red")+ labs(x = "Fitted Values", y = "Studentized Residual") 
# 

# qqplot.resid <- qplot(sample = mt$studentized.residuals, stat="qq") + labs(x = "Theoretical Values", y = "Observed Values") 
# qqplot.resid


```

## References

1. An introduction to Statistical Learning (James - Witten - Hastie - Tibshirani)
2. R in Action (Kabacoff)
3. Discovering Statistics Using R (Field)

Source code available on Github https://github.com/stefMT2970/mtCars
